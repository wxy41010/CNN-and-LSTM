import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
import numpy as np
import torch

# === 1. åŠ è½½æ•°æ® ===
df = pd.read_csv('merged_ctu13.csv', low_memory=False)
df.columns = df.columns.str.strip()  # æ¸…é™¤åˆ—åç©ºæ ¼

# === 2. é€‰æ‹©è®­ç»ƒå­—æ®µ ===
features = ['Dur', 'Proto', 'Sport', 'Dport', 'TotBytes', 'TotPkts']
df = df[features + ['Label']].dropna()

# === 3. åè®®ç±»å‹ç¼–ç  ===
df['Proto'] = LabelEncoder().fit_transform(df['Proto'].astype(str))

# === 4. Sport å’Œ Dport è½¬æ¢ä¸ºæ•°å€¼ï¼Œéæ³•è®¾ä¸º NaN ===
for port in ['Sport', 'Dport']:
    df[port] = pd.to_numeric(df[port], errors='coerce')
df.dropna(subset=['Sport', 'Dport'], inplace=True)

# === 5. æ ‡ç­¾äºŒå€¼åŒ–ï¼ˆæ˜¯å¦ä¸º Botnetï¼‰===
df['Label'] = df['Label'].apply(lambda x: 1 if 'Botnet' in str(x) else 0)

# === 6. æå–ç‰¹å¾å¹¶æ ‡å‡†åŒ–å‰æ£€æŸ¥ ===
X = df[features].values
y = df['Label'].values

print("ğŸ” ç‰¹å¾åŸå§‹æœ€å¤§å€¼:", np.max(X, axis=0))
print("ğŸ” ç‰¹å¾åŸå§‹æœ€å°å€¼:", np.min(X, axis=0))

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

print("âœ… ç‰¹å¾æ ‡å‡†åŒ–åæœ€å¤§å€¼:", np.max(X_scaled, axis=0))
print("âœ… ç‰¹å¾æ ‡å‡†åŒ–åæœ€å°å€¼:", np.min(X_scaled, axis=0))

# === 7. æ•°æ®é›†åˆ’åˆ† ===
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)

# === 8. æ ‡ç­¾åˆ†å¸ƒæ‰“å° ===
print("ğŸ¯ è®­ç»ƒé›†æ ‡ç­¾åˆ†å¸ƒ:", np.bincount(y_train))
print("ğŸ¯ æµ‹è¯•é›†æ ‡ç­¾åˆ†å¸ƒ:", np.bincount(y_test))

# === 9. è½¬æ¢ä¸º PyTorch å¼ é‡ ===
X_train_tensor = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)
X_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)
y_train_tensor = torch.tensor(y_train, dtype=torch.long)
y_test_tensor = torch.tensor(y_test, dtype=torch.long)

# === 10. ä¿å­˜å¼ é‡æ–‡ä»¶ ===
torch.save((X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor), 'cnn_data.pt')
print("âœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼Œå·²ä¿å­˜ä¸º cnn_data.pt")
